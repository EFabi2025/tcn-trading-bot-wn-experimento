#!/usr/bin/env python3
"""
ðŸ§  MODELO TCN ANTI-SESGO CON CONCIENCIA DE RÃ‰GIMEN
=================================================

ImplementaciÃ³n de la arquitectura TCN dual que recibe:
1. Datos de precios y features tÃ©cnicos (secuencias temporales)
2. Contexto de rÃ©gimen de mercado (one-hot encoding)

Esta arquitectura elimina sesgos porque el modelo "sabe" explÃ­citamente
en quÃ© tipo de mercado estÃ¡ operando.
"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Nadam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import pickle
from typing import Tuple, Dict, List, Optional
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n TensorFlow para Apple Silicon
tf.config.experimental.enable_mlir_bridge()
physical_devices = tf.config.experimental.list_physical_devices('GPU')
if len(physical_devices) > 0:
    print("âœ… Metal GPU available for acceleration")
else:
    print("âš ï¸ Metal GPU not detected, using CPU")

class TemporalConvNet(layers.Layer):
    """
    ImplementaciÃ³n de Temporal Convolutional Network (TCN)
    
    TCN es superior a LSTM/GRU para trading porque:
    - Campo receptivo mÃ¡s amplio
    - ParalelizaciÃ³n eficiente
    - Sin problemas de gradientes desvanecientes
    - Predicciones consistentes
    """
    
    def __init__(self, nb_filters=48, kernel_size=2, nb_stacks=2, 
                 dilations=[1, 2, 4, 8, 16, 32], dropout_rate=0.3, 
                 use_skip_connections=True, activation='relu', name='tcn', **kwargs):
        super(TemporalConvNet, self).__init__(name=name, **kwargs)
        
        self.nb_filters = nb_filters
        self.kernel_size = kernel_size
        self.nb_stacks = nb_stacks
        self.dilations = dilations
        self.dropout_rate = dropout_rate
        self.use_skip_connections = use_skip_connections
        self.activation = activation
        
        # Crear capas TCN
        self.tcn_layers = []
        
        for stack in range(nb_stacks):
            stack_layers = []
            for i, dilation in enumerate(dilations):
                # Capa convolucional dilatada
                conv_layer = layers.Conv1D(
                    filters=nb_filters,
                    kernel_size=kernel_size,
                    dilation_rate=dilation,
                    padding='causal',  # Fundamental para no ver el futuro
                    activation=None,
                    name=f'tcn_conv_s{stack}_d{dilation}'
                )
                
                # NormalizaciÃ³n y activaciÃ³n
                norm_layer = layers.LayerNormalization(name=f'tcn_norm_s{stack}_d{dilation}')
                activation_layer = layers.Activation(activation, name=f'tcn_act_s{stack}_d{dilation}')
                dropout_layer = layers.SpatialDropout1D(dropout_rate, name=f'tcn_drop_s{stack}_d{dilation}')
                
                stack_layers.append({
                    'conv': conv_layer,
                    'norm': norm_layer,
                    'activation': activation_layer,
                    'dropout': dropout_layer
                })
            
            self.tcn_layers.append(stack_layers)
        
        # Capa de output
        self.output_conv = layers.Conv1D(
            filters=nb_filters,
            kernel_size=1,
            padding='same',
            activation=None,
            name='tcn_output_conv'
        )
        
        # Global pooling para obtener representaciÃ³n final
        self.global_pool = layers.GlobalMaxPooling1D(name='tcn_global_pool')
    
    def call(self, inputs, training=None):
        x = inputs
        
        # Aplicar stacks de TCN
        for stack_idx, stack_layers in enumerate(self.tcn_layers):
            stack_input = x
            
            for layer_dict in stack_layers:
                # ConvoluciÃ³n dilatada
                x = layer_dict['conv'](x)
                x = layer_dict['norm'](x, training=training)
                x = layer_dict['activation'](x)
                x = layer_dict['dropout'](x, training=training)
            
            # Skip connection si estÃ¡ habilitado
            if self.use_skip_connections and x.shape[-1] == stack_input.shape[-1]:
                x = layers.Add(name=f'tcn_skip_s{stack_idx}')([x, stack_input])
        
        # ProyecciÃ³n final y pooling
        x = self.output_conv(x)
        x = self.global_pool(x)
        
        return x
    
    def get_config(self):
        config = super(TemporalConvNet, self).get_config()
        config.update({
            'nb_filters': self.nb_filters,
            'kernel_size': self.kernel_size,
            'nb_stacks': self.nb_stacks,
            'dilations': self.dilations,
            'dropout_rate': self.dropout_rate,
            'use_skip_connections': self.use_skip_connections,
            'activation': self.activation
        })
        return config

class RegimeAwareTCNModel:
    """
    Modelo TCN consciente del rÃ©gimen de mercado
    
    Arquitectura innovadora:
    - Input 1: Secuencias temporales de precios/features
    - Input 2: Contexto de rÃ©gimen de mercado (bull/bear/sideways)
    - Output: DecisiÃ³n de trading balanceada (BUY/HOLD/SELL)
    """
    
    def __init__(self, input_shape_prices=(60, 50), regime_shape=(3,)):
        self.input_shape_prices = input_shape_prices
        self.regime_shape = regime_shape
        self.model = None
        self.history = None
        self.scalers = {}
    
    def create_model(self) -> Model:
        """
        Crea el modelo TCN consciente del rÃ©gimen
        
        InnovaciÃ³n clave: El modelo recibe explÃ­citamente el contexto
        de mercado, eliminando la necesidad de "adivinar" el rÃ©gimen
        """
        print("ðŸ§  Building Regime-Aware TCN Model...")
        
        # === ENTRADA 1: DATOS DE PRECIOS Y FEATURES TÃ‰CNICOS ===
        price_input = layers.Input(
            shape=self.input_shape_prices, 
            name='price_features',
            dtype=tf.float32
        )
        
        # TCN Principal - Procesamiento temporal avanzado
        tcn_output = TemporalConvNet(
            nb_filters=48,                      # Optimizado para Apple Silicon
            kernel_size=2,                      # Kernel pequeÃ±o para granularidad
            nb_stacks=2,                        # Balance complejidad/velocidad
            dilations=[1, 2, 4, 8, 16, 32],    # Campo receptivo de 64 perÃ­odos
            dropout_rate=0.3,                  # RegularizaciÃ³n moderada
            use_skip_connections=True,         # Mejor flujo de gradientes
            activation='relu',
            name='tcn_temporal_processor'
        )(price_input)
        
        # === ENTRADA 2: CONTEXTO DE RÃ‰GIMEN DE MERCADO ===
        regime_input = layers.Input(
            shape=self.regime_shape, 
            name='market_regime',
            dtype=tf.float32
        )
        
        # Procesar contexto de rÃ©gimen
        regime_processed = layers.Dense(
            32, 
            activation='relu',
            name='regime_processor'
        )(regime_input)
        
        regime_processed = layers.Dropout(
            0.2, 
            name='regime_dropout'
        )(regime_processed)
        
        # === FUSIÃ“N DE INFORMACIÃ“N TEMPORAL + CONTEXTUAL ===
        combined_features = layers.Concatenate(
            name='feature_fusion'
        )([tcn_output, regime_processed])
        
        # === CAPAS DE DECISIÃ“N ESPECIALIZADAS ===
        # Primera capa: IntegraciÃ³n de features
        x = layers.Dense(
            128, 
            activation='relu',
            kernel_initializer='he_normal',
            name='decision_layer_1'
        )(combined_features)
        
        x = layers.BatchNormalization(name='bn_1')(x)
        x = layers.Dropout(0.4, name='dropout_1')(x)  # Dropout agresivo
        
        # Segunda capa: Refinamiento
        x = layers.Dense(
            64, 
            activation='relu',
            kernel_initializer='he_normal',
            name='decision_layer_2'
        )(x)
        
        x = layers.BatchNormalization(name='bn_2')(x)
        x = layers.Dropout(0.3, name='dropout_2')(x)
        
        # Tercera capa: Pre-decisiÃ³n
        x = layers.Dense(
            32, 
            activation='relu',
            kernel_initializer='he_normal',
            name='decision_layer_3'
        )(x)
        
        x = layers.Dropout(0.2, name='dropout_3')(x)
        
        # === SALIDA BALANCEADA: BUY, HOLD, SELL ===
        output = layers.Dense(
            3, 
            activation='softmax',
            kernel_initializer='glorot_uniform',  # InicializaciÃ³n balanceada
            bias_initializer='zeros',             # Sin sesgo inicial
            name='trading_decision'
        )(x)
        
        # Crear modelo
        model = Model(
            inputs=[price_input, regime_input], 
            outputs=output,
            name='TCN_Anti_Bias_Trading_Model'
        )
        
        # === COMPILACIÃ“N CON CONFIGURACIÃ“N ANTI-SESGO ===
        model.compile(
            optimizer=Nadam(
                learning_rate=0.001,
                beta_1=0.9,
                beta_2=0.999,
                epsilon=1e-7
            ),
            loss='categorical_crossentropy',
            metrics=[
                'accuracy',
                tf.keras.metrics.Precision(name='precision'),
                tf.keras.metrics.Recall(name='recall'),
                tf.keras.metrics.AUC(name='auc')
            ]
        )
        
        self.model = model
        
        print(f"âœ… Model created with {model.count_params():,} parameters")
        print(f"   Input shapes: {self.input_shape_prices} (prices) + {self.regime_shape} (regime)")
        
        return model
    
    def calculate_class_weights(self, y_train: np.ndarray) -> Dict[int, float]:
        """
        Calcula pesos balanceados para clases
        
        CRÃTICO para anti-sesgo: Asegura que cada clase (BUY/HOLD/SELL)
        tenga igual importancia durante el entrenamiento
        """
        class_counts = np.sum(y_train, axis=0)
        total_samples = len(y_train)
        
        class_weights = {}
        for i in range(len(class_counts)):
            if class_counts[i] > 0:
                class_weights[i] = total_samples / (len(class_counts) * class_counts[i])
            else:
                class_weights[i] = 1.0
        
        print(f"ðŸ“Š Class distribution in training data:")
        labels = ['BUY', 'HOLD', 'SELL']
        for i, (count, weight) in enumerate(zip(class_counts, class_weights.values())):
            percentage = count / total_samples * 100
            print(f"   {labels[i]}: {count:,} samples ({percentage:.1f}%) - weight: {weight:.3f}")
        
        return class_weights
    
    def create_callbacks(self, model_save_path: str = 'models/tcn_anti_bias_best.h5') -> List:
        """Crear callbacks para entrenamiento"""
        
        # Crear directorio si no existe
        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
        
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True,
                verbose=1,
                mode='min'
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-6,
                verbose=1,
                mode='min'
            ),
            ModelCheckpoint(
                model_save_path,
                monitor='val_loss',
                save_best_only=True,
                save_weights_only=False,
                verbose=1,
                mode='min'
            )
        ]
        
        return callbacks
    
    def train(self, X_train_price: np.ndarray, X_train_regime: np.ndarray, y_train: np.ndarray,
              X_val_price: np.ndarray, X_val_regime: np.ndarray, y_val: np.ndarray,
              epochs: int = 100, batch_size: int = 64, model_save_path: str = 'models/tcn_anti_bias_best.h5', 
              callbacks: List = None) -> tf.keras.callbacks.History:
        """
        Entrenar el modelo TCN anti-sesgo
        """
        print("ðŸƒâ€â™‚ï¸ Starting anti-bias TCN training...")
        
        if self.model is None:
            self.create_model()
        
        # Calcular pesos balanceados (CRÃTICO para anti-sesgo)
        class_weights = self.calculate_class_weights(y_train)
        
        # Usar callbacks personalizados si se proporcionan, sino crear los por defecto
        if callbacks is None:
            callbacks = self.create_callbacks(model_save_path)
        
        # Entrenar modelo
        print(f"   Training samples: {len(X_train_price):,}")
        print(f"   Validation samples: {len(X_val_price):,}")
        print(f"   Epochs: {epochs}, Batch size: {batch_size}")
        
        history = self.model.fit(
            [X_train_price, X_train_regime], y_train,
            validation_data=([X_val_price, X_val_regime], y_val),
            epochs=epochs,
            batch_size=batch_size,
            class_weight=class_weights,  # CRÃTICO para balanceado
            callbacks=callbacks,
            verbose=1,
            shuffle=True
        )
        
        self.history = history
        
        print("âœ… Training completed!")
        return history
    
    def predict(self, X_price: np.ndarray, X_regime: np.ndarray) -> np.ndarray:
        """Realizar predicciones con el modelo"""
        if self.model is None:
            raise ValueError("Model not trained yet. Call train() first.")
        
        predictions = self.model.predict([X_price, X_regime], verbose=0)
        return predictions
    
    def evaluate_by_regime(self, X_test_price: np.ndarray, X_test_regime: np.ndarray, 
                          y_test: np.ndarray) -> Dict[str, Dict[str, float]]:
        """
        EvaluaciÃ³n especÃ­fica por rÃ©gimen de mercado
        
        CRÃTICO: Verifica que el modelo funcione bien en TODOS los regÃ­menes
        """
        print("ðŸ“Š Evaluating model performance by market regime...")
        
        predictions = self.predict(X_test_price, X_test_regime)
        
        # Identificar rÃ©gimen de cada muestra
        regime_names = ['bull', 'bear', 'sideways']
        regime_indices = np.argmax(X_test_regime, axis=1)
        
        results = {}
        
        for regime_idx, regime_name in enumerate(regime_names):
            regime_mask = regime_indices == regime_idx
            
            if not np.any(regime_mask):
                print(f"   âš ï¸ No {regime_name} samples in test set")
                continue
            
            regime_y_true = y_test[regime_mask]
            regime_y_pred = predictions[regime_mask]
            
            # Calcular mÃ©tricas
            y_true_labels = np.argmax(regime_y_true, axis=1)
            y_pred_labels = np.argmax(regime_y_pred, axis=1)
            
            accuracy = np.mean(y_true_labels == y_pred_labels)
            
            # Precision y recall por clase
            labels = ['BUY', 'HOLD', 'SELL']
            precision_per_class = []
            recall_per_class = []
            
            for class_idx in range(3):
                true_positives = np.sum((y_true_labels == class_idx) & (y_pred_labels == class_idx))
                predicted_positives = np.sum(y_pred_labels == class_idx)
                actual_positives = np.sum(y_true_labels == class_idx)
                
                precision = true_positives / predicted_positives if predicted_positives > 0 else 0
                recall = true_positives / actual_positives if actual_positives > 0 else 0
                
                precision_per_class.append(precision)
                recall_per_class.append(recall)
            
            avg_precision = np.mean(precision_per_class)
            avg_recall = np.mean(recall_per_class)
            f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0
            
            results[regime_name] = {
                'samples': int(np.sum(regime_mask)),
                'accuracy': float(accuracy),
                'precision': float(avg_precision),
                'recall': float(avg_recall),
                'f1_score': float(f1_score),
                'precision_per_class': [float(p) for p in precision_per_class],
                'recall_per_class': [float(r) for r in recall_per_class]
            }
            
            print(f"   ðŸ“Š {regime_name.upper()} regime ({results[regime_name]['samples']} samples):")
            print(f"      Accuracy: {accuracy:.3f}")
            print(f"      Precision: {avg_precision:.3f}")
            print(f"      Recall: {avg_recall:.3f}")
            print(f"      F1-Score: {f1_score:.3f}")
        
        # AnÃ¡lisis de consistencia (objetivo anti-sesgo)
        if len(results) >= 2:
            accuracies = [r['accuracy'] for r in results.values()]
            accuracy_variance = np.var(accuracies)
            accuracy_std = np.std(accuracies)
            
            print(f"\nðŸŽ¯ ANTI-BIAS ANALYSIS:")
            print(f"   Accuracy variance across regimes: {accuracy_variance:.6f}")
            print(f"   Accuracy standard deviation: {accuracy_std:.3f}")
            
            if accuracy_std < 0.05:  # Menos de 5% de diferencia
                print(f"   âœ… Model is WELL-BALANCED across regimes!")
            elif accuracy_std < 0.10:
                print(f"   âš ï¸ Model has moderate bias across regimes")
            else:
                print(f"   âŒ Model has significant bias across regimes!")
        
        return results
    
    def save_model(self, filepath: str):
        """Guardar modelo completo"""
        if self.model is None:
            raise ValueError("No model to save")
        
        self.model.save(filepath)
        print(f"ðŸ’¾ Model saved to {filepath}")
    
    def load_model(self, filepath: str):
        """Cargar modelo previamente entrenado"""
        self.model = tf.keras.models.load_model(filepath, custom_objects={
            'TemporalConvNet': TemporalConvNet
        })
        print(f"ðŸ“‚ Model loaded from {filepath}")
    
    def get_model_summary(self):
        """Mostrar resumen del modelo"""
        if self.model is None:
            print("âŒ No model created yet")
            return
        
        print("ðŸ§  Model Architecture Summary:")
        self.model.summary()
        
        # Visualizar arquitectura
        try:
            tf.keras.utils.plot_model(
                self.model, 
                to_file='tcn_anti_bias_architecture.png',
                show_shapes=True,
                show_layer_names=True,
                rankdir='TB'
            )
            print("ðŸ“Š Architecture diagram saved to 'tcn_anti_bias_architecture.png'")
        except:
            print("âš ï¸ Could not save architecture diagram")

def main():
    """Demo de la arquitectura TCN anti-sesgo"""
    print("ðŸš€ Starting TCN Anti-Bias Model Demo")
    
    # Crear datos de prueba
    batch_size = 100
    sequence_length = 60
    num_features = 50
    
    # Simular datos de entrenamiento
    X_train_price = np.random.randn(batch_size, sequence_length, num_features).astype(np.float32)
    X_train_regime = np.random.randint(0, 2, (batch_size, 3)).astype(np.float32)
    
    # Normalizar regime a one-hot
    for i in range(batch_size):
        X_train_regime[i] = 0
        X_train_regime[i, np.random.randint(0, 3)] = 1
    
    y_train = np.random.randint(0, 2, (batch_size, 3)).astype(np.float32)
    
    # Normalizar labels a one-hot
    for i in range(batch_size):
        y_train[i] = 0
        y_train[i, np.random.randint(0, 3)] = 1
    
    print(f"ðŸ“Š Demo data shapes:")
    print(f"   X_train_price: {X_train_price.shape}")
    print(f"   X_train_regime: {X_train_regime.shape}")
    print(f"   y_train: {y_train.shape}")
    
    # Crear modelo
    model = RegimeAwareTCNModel(
        input_shape_prices=(sequence_length, num_features),
        regime_shape=(3,)
    )
    
    try:
        # Crear arquitectura
        print("\n1ï¸âƒ£ Creating model architecture...")
        model.create_model()
        
        # Mostrar resumen
        print("\n2ï¸âƒ£ Model summary...")
        model.get_model_summary()
        
        # Simular predicciÃ³n
        print("\n3ï¸âƒ£ Testing prediction...")
        predictions = model.predict(X_train_price[:10], X_train_regime[:10])
        print(f"âœ… Predictions shape: {predictions.shape}")
        print(f"   Sample prediction: {predictions[0]}")
        
        print("\nâœ… TCN Anti-Bias Model demo completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error in demo: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 